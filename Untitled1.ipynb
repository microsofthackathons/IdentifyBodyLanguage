{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16d4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-face\n",
      "  Downloading azure_cognitiveservices_vision_face-0.6.0-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-face) (0.7.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-vision-face) (1.1.28)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2021.10.8)\n",
      "Requirement already satisfied: azure-core>=1.24.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.25.1)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (4.1.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\skarasala\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.2.1)\n",
      "Installing collected packages: azure-cognitiveservices-vision-face\n",
      "Successfully installed azure-cognitiveservices-vision-face-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade azure-cognitiveservices-vision-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95423f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "\n",
      "DETECT FACES\n",
      "\n"
     ]
    },
    {
     "ename": "APIErrorException",
     "evalue": "(InvalidRequest) Invalid request has been sent.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 97>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m single_image_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(single_face_image_url)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# We use detection model 3 to get better performance.\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m detected_faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_with_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_face_image_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetection_01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m detected_faces:\n\u001b[0;32m     99\u001b[0m \t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo face detected from image \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(single_image_name))\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\cognitiveservices\\vision\\face\\operations\\_face_operations.py:547\u001b[0m, in \u001b[0;36mFaceOperations.detect_with_url\u001b[1;34m(self, url, return_face_id, return_face_landmarks, return_face_attributes, recognition_model, return_recognition_model, detection_model, face_id_time_to_live, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    544\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moperation_config)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mAPIErrorException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize, response)\n\u001b[0;32m    549\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mAPIErrorException\u001b[0m: (InvalidRequest) Invalid request has been sent."
     ]
    }
   ],
   "source": [
    "# <snippet_imports>\n",
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition\n",
    "# </snippet_imports>\n",
    "\n",
    "'''\n",
    "Face Quickstart\n",
    "Examples include:\n",
    "    - Detect Faces: detects faces in an image.\n",
    "    - Find Similar: finds a similar face in an image using ID from Detect Faces.\n",
    "    - Verify: compares two images to check if they are the same person or not.\n",
    "    - Person Group: creates a person group and uses it to identify faces in other images.\n",
    "    - Large Person Group: similar to person group, but with different API calls to handle scale.\n",
    "    - Face List: creates a list of single-faced images, then gets data from list.\n",
    "    - Large Face List: creates a large list for single-faced images, trains it, then gets data.\n",
    "Prerequisites:\n",
    "    - Python 3+\n",
    "    - Install Face SDK: pip install azure-cognitiveservices-vision-face\n",
    "    - In your root folder, add all images downloaded from here:\n",
    "      https://github.com/Azure-examples/cognitive-services-sample-data-files/tree/master/Face/images\n",
    "How to run:\n",
    "    - Run from command line or an IDE\n",
    "    - If the Person Group or Large Person Group (or Face List / Large Face List) examples get\n",
    "      interrupted after creation, be sure to delete your created person group (lists) from the API,\n",
    "      as you cannot create a new one with the same name. Use 'Person group - List' to check them all,\n",
    "      and 'Person Group - Delete' to remove one. The examples have a delete function in them, but at the end.\n",
    "      Person Group API: https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395244\n",
    "      Face List API: https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524d\n",
    "References:\n",
    "    - Documentation: https://docs.microsoft.com/en-us/azure/cognitive-services/face/\n",
    "    - SDK: https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-vision-face/azure.cognitiveservices.vision.face?view=azure-python\n",
    "    - All Face APIs: https://docs.microsoft.com/en-us/azure/cognitive-services/face/APIReference\n",
    "'''\n",
    "\n",
    "# <snippet_subvars>\n",
    "# This key will serve all examples in this document.\n",
    "KEY = \"a87dad4b310d4597a603e964fd2cd153\"\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = \"https://aiblfaceapi.cognitiveservices.azure.com/\"\n",
    "# </snippet_subvars>\n",
    "\n",
    "# <snippet_verify_baseurl>\n",
    "# Base url for the Verify and Facelist/Large Facelist operations\n",
    "IMAGE_BASE_URL = 'https://csdx.blob.core.windows.net/resources/Face/Images/'\n",
    "# </snippet_verify_baseurl>\n",
    "\n",
    "# <snippet_persongroupvars>\n",
    "# Used in the Person Group Operations and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Used for the Delete Person Group example.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "# </snippet_persongroupvars>\n",
    "\n",
    "'''\n",
    "Authenticate\n",
    "All examples use the same client.\n",
    "'''\n",
    "# <snippet_auth>\n",
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "# </snippet_auth>\n",
    "'''\n",
    "END - Authenticate\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect faces \n",
    "Detect faces in two images (get ID), draw rectangle around a third image.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('DETECT FACES')\n",
    "print()\n",
    "# <snippet_detect>\n",
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://www.biography.com/.image/t_share/MTQ1MzAyNzYzOTgxNTE0NTEz/john-f-kennedy---mini-biography.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_01')\n",
    "if not detected_faces:\n",
    "\traise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Display the detected face ID in the first single-face image.\n",
    "# Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
    "print('Detected face ID from', single_image_name, ':')\n",
    "for face in detected_faces: print (face.face_id)\n",
    "print()\n",
    "\n",
    "# Save this ID for use in Find Similar\n",
    "first_image_face_ID = detected_faces[0].face_id\n",
    "# </snippet_detect>\n",
    "\n",
    "# <snippet_detectgroup>\n",
    "# Detect the faces in an image that contains multiple faces\n",
    "# Each detected face gets assigned a new ID\n",
    "multi_face_image_url = \"http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg\"\n",
    "multi_image_name = os.path.basename(multi_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces2 = face_client.face.detect_with_url(url=multi_face_image_url, detection_model='detection_03')\n",
    "# </snippet_detectgroup>\n",
    "\n",
    "print('Detected face IDs from', multi_image_name, ':')\n",
    "if not detected_faces2:\n",
    "\traise Exception('No face detected from image {}.'.format(multi_image_name))\n",
    "else:\n",
    "    for face in detected_faces2:\n",
    "        print(face.face_id)\n",
    "print()\n",
    "\n",
    "'''\n",
    "Print image and draw rectangles around faces\n",
    "'''\n",
    "# <snippet_frame>\n",
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://raw.githubusercontent.com/Microsoft/Cognitive-Face-Windows/master/Data/detection1.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03')\n",
    "if not detected_faces:\n",
    "\traise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))\n",
    "\n",
    "def drawFaceRectangles() :\n",
    "# Download the image from the url\n",
    "    response = requests.get(single_face_image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "    print('Drawing rectangle around face... see popup for results.')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_faces:\n",
    "        draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "# Display the image in the default image browser.\n",
    "    img.show()\n",
    "\n",
    "# Uncomment this to show the face rectangles.\n",
    "#    drawFaceRectangles()\n",
    "# </snippet_frame>\n",
    "\n",
    "print()\n",
    "'''\n",
    "END - Detect faces\n",
    "'''\n",
    "\n",
    "'''\n",
    "Find a similar face\n",
    "This example uses detected faces in a group photo to find a similar face using a single-faced image as query.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('FIND SIMILAR')\n",
    "print()\n",
    "# <snippet_findsimilar>\n",
    "# Search through faces detected in group image for the single face from first image.\n",
    "# First, create a list of the face IDs found in the second image.\n",
    "second_image_face_IDs = list(map(lambda x: x.face_id, detected_faces2))\n",
    "# Next, find similar face IDs like the one detected in the first image.\n",
    "similar_faces = face_client.face.find_similar(face_id=first_image_face_ID, face_ids=second_image_face_IDs)\n",
    "if not similar_faces:\n",
    "\tprint('No similar faces found in', multi_image_name, '.')\n",
    "# </snippet_findsimilar>\n",
    "\n",
    "# <snippet_findsimilar_print>\n",
    "# Print the details of the similar faces detected\n",
    "else:\n",
    "\tprint('Similar faces found in', multi_image_name + ':')\n",
    "\tfor face in similar_faces:\n",
    "\t\tfirst_image_face_ID = face.face_id\n",
    "\t\t# The similar face IDs of the single face image and the group image do not need to match, \n",
    "\t\t# they are only used for identification purposes in each image.\n",
    "\t\t# The similar faces are matched using the Cognitive Services algorithm in find_similar().\n",
    "\t\tface_info = next(x for x in detected_faces2 if x.face_id == first_image_face_ID)\n",
    "\t\tif face_info:\n",
    "\t\t\tprint('  Face ID: ', first_image_face_ID)\n",
    "\t\t\tprint('  Face rectangle:')\n",
    "\t\t\tprint('    Left: ', str(face_info.face_rectangle.left))\n",
    "\t\t\tprint('    Top: ', str(face_info.face_rectangle.top))\n",
    "\t\t\tprint('    Width: ', str(face_info.face_rectangle.width))\n",
    "\t\t\tprint('    Height: ', str(face_info.face_rectangle.height))\n",
    "# </snippet_findsimilar_print>\n",
    "print()\n",
    "'''\n",
    "END - Find Similar\n",
    "'''\n",
    "\n",
    "'''\n",
    "Verify\n",
    "The Verify operation takes a face ID from DetectedFace or PersistedFace and either another face ID or a Person object \n",
    "and determines whether they belong to the same person. If you pass in a Person object, you can optionally pass in a \n",
    "PersonGroup to which that Person belongs to improve performance.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('VERIFY')\n",
    "print()\n",
    "# <snippet_verify_photos>\n",
    "# Create a list to hold the target photos of the same person\n",
    "target_image_file_names = ['Family1-Dad1.jpg', 'Family1-Dad2.jpg']\n",
    "# The source photos contain this person\n",
    "source_image_file_name1 = 'Family1-Dad3.jpg'\n",
    "source_image_file_name2 = 'Family1-Son1.jpg'\n",
    "# </snippet_verify_photos>\n",
    "\n",
    "# <snippet_verify_detect>\n",
    "# Detect face(s) from source image 1, returns a list[DetectedFaces]\n",
    "# We use detection model 3 to get better performance.\n",
    "detected_faces1 = face_client.face.detect_with_url(IMAGE_BASE_URL + source_image_file_name1, detection_model='detection_03')\n",
    "# Add the returned face's face ID\n",
    "source_image1_id = detected_faces1[0].face_id\n",
    "print('{} face(s) detected from image {}.'.format(len(detected_faces1), source_image_file_name1))\n",
    "\n",
    "# Detect face(s) from source image 2, returns a list[DetectedFaces]\n",
    "detected_faces2 = face_client.face.detect_with_url(IMAGE_BASE_URL + source_image_file_name2, detection_model='detection_03')\n",
    "# Add the returned face's face ID\n",
    "source_image2_id = detected_faces2[0].face_id\n",
    "print('{} face(s) detected from image {}.'.format(len(detected_faces2), source_image_file_name2))\n",
    "\n",
    "# List for the target face IDs (uuids)\n",
    "detected_faces_ids = []\n",
    "# Detect faces from target image url list, returns a list[DetectedFaces]\n",
    "for image_file_name in target_image_file_names:\n",
    "\t# We use detection model 3 to get better performance.\n",
    "    detected_faces = face_client.face.detect_with_url(IMAGE_BASE_URL + image_file_name, detection_model='detection_03')\n",
    "    # Add the returned face's face ID\n",
    "    detected_faces_ids.append(detected_faces[0].face_id)\n",
    "    print('{} face(s) detected from image {}.'.format(len(detected_faces), image_file_name))\n",
    "# </snippet_verify_detect>\n",
    "\n",
    "# <snippet_verify>\n",
    "# Verification example for faces of the same person. The higher the confidence, the more identical the faces in the images are.\n",
    "# Since target faces are the same person, in this example, we can use the 1st ID in the detected_faces_ids list to compare.\n",
    "verify_result_same = face_client.face.verify_face_to_face(source_image1_id, detected_faces_ids[0])\n",
    "print('Faces from {} & {} are of the same person, with confidence: {}'\n",
    "    .format(source_image_file_name1, target_image_file_names[0], verify_result_same.confidence)\n",
    "    if verify_result_same.is_identical\n",
    "    else 'Faces from {} & {} are of a different person, with confidence: {}'\n",
    "        .format(source_image_file_name1, target_image_file_names[0], verify_result_same.confidence))\n",
    "\n",
    "# Verification example for faces of different persons.\n",
    "# Since target faces are same person, in this example, we can use the 1st ID in the detected_faces_ids list to compare.\n",
    "verify_result_diff = face_client.face.verify_face_to_face(source_image2_id, detected_faces_ids[0])\n",
    "print('Faces from {} & {} are of the same person, with confidence: {}'\n",
    "    .format(source_image_file_name2, target_image_file_names[0], verify_result_diff.confidence)\n",
    "    if verify_result_diff.is_identical\n",
    "    else 'Faces from {} & {} are of a different person, with confidence: {}'\n",
    "        .format(source_image_file_name2, target_image_file_names[0], verify_result_diff.confidence))\n",
    "# </snippet_verify>\n",
    "print()\n",
    "'''\n",
    "END - VERIFY\n",
    "'''\n",
    "\n",
    "'''\n",
    "Create/Train/Detect/Identify Person Group\n",
    "This example creates a Person Group, then trains it. It can then be used to detect and identify faces in other group images.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('PERSON GROUP OPERATIONS')\n",
    "print()\n",
    "\n",
    "# <snippet_persongroup_create>\n",
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, \"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, \"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, \"Child\")\n",
    "# </snippet_persongroup_create>\n",
    "\n",
    "# <snippet_persongroup_assign>\n",
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith(\"w\")]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith(\"m\")]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith(\"ch\")]\n",
    "\n",
    "# Add to a woman person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "\t# Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "# Add to a man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "\t# Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "# Add to a child person\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "\t# Check if the image is of sufficent quality for recognition.\n",
    "    sufficientQuality = True\n",
    "    detected_faces = face_client.face.detect_with_url(url=single_face_image_url, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "    for face in detected_faces:\n",
    "        if face.face_attributes.quality_for_recognition != QualityForRecognition.high:\n",
    "            sufficientQuality = False\n",
    "            break\n",
    "    if not sufficientQuality: continue\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)\n",
    "# </snippet_persongroup_assign>\n",
    "\n",
    "# <snippet_persongroup_train>\n",
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the person group...')\n",
    "# Train the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)\n",
    "# </snippet_persongroup_train>\n",
    "\n",
    "# <snippet_identify_testimage>\n",
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "test_image_array = glob.glob('test-image-person-group.jpg')\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "print('Pausing for 60 seconds to avoid triggering rate limit on free account...')\n",
    "time.sleep (60)\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "# We use detection model 3 to get better performance, recognition model 4 to support quality for recognition attribute.\n",
    "faces = face_client.face.detect_with_stream(image, detection_model='detection_03', recognition_model='recognition_04', return_face_attributes=['qualityForRecognition'])\n",
    "for face in faces:\n",
    "    # Only take the face if it is of sufficient quality.\n",
    "    if face.face_attributes.quality_for_recognition == QualityForRecognition.high or face.face_attributes.quality_for_recognition == QualityForRecognition.medium:\n",
    "        face_ids.append(face.face_id)\n",
    "# </snippet_identify_testimage>\n",
    "\n",
    "# <snippet_identify>\n",
    "# Identify faces\n",
    "results = face_client.face.identify(face_ids, PERSON_GROUP_ID)\n",
    "print('Identifying faces in {}'.format(os.path.basename(image.name)))\n",
    "if not results:\n",
    "    print('No person identified in the person group for faces from {}.'.format(os.path.basename(image.name)))\n",
    "for person in results:\n",
    "\tif len(person.candidates) > 0:\n",
    "\t\tprint('Person for face ID {} is identified in {} with a confidence of {}.'.format(person.face_id, os.path.basename(image.name), person.candidates[0].confidence)) # Get topmost confidence score\n",
    "\telse:\n",
    "\t\tprint('No person identified for face ID {} in {}.'.format(person.face_id, os.path.basename(image.name)))\n",
    "# </snippet_identify>\n",
    "print()\n",
    "'''\n",
    "END - Create/Train/Detect/Identify Person Group\n",
    "'''\n",
    "\n",
    "'''\n",
    "Create/List/Delete Large Person Group\n",
    "Uses the same list used for creating a regular-sized person group.\n",
    "The operations are similar in structure as the Person Group example.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('LARGE PERSON GROUP OPERATIONS')\n",
    "print()\n",
    "\n",
    "# Large Person Group ID, should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "LARGE_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)\n",
    "\n",
    "# Create empty Large Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "# The name and the ID can be either the same or different\n",
    "print('Large person group:', LARGE_PERSON_GROUP_ID)\n",
    "face_client.large_person_group.create(large_person_group_id=LARGE_PERSON_GROUP_ID, name=LARGE_PERSON_GROUP_ID)\n",
    "\n",
    "# Define woman friend , by creating a large person group person\n",
    "woman = face_client.large_person_group_person.create(LARGE_PERSON_GROUP_ID, \"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.large_person_group_person.create(LARGE_PERSON_GROUP_ID, \"Man\")\n",
    "# Define child friend\n",
    "child = face_client.large_person_group_person.create(LARGE_PERSON_GROUP_ID, \"Child\")\n",
    "\n",
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith(\"w\")]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith(\"m\")]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith(\"ch\")]\n",
    "\n",
    "# Add to a woman person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    face_client.large_person_group_person.add_face_from_stream(LARGE_PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "# Add to a man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    face_client.large_person_group_person.add_face_from_stream(LARGE_PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "# Add to a child person\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    face_client.large_person_group_person.add_face_from_stream(LARGE_PERSON_GROUP_ID, child.person_id, ch)\n",
    "\n",
    "'''\n",
    "Train LargePersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the large person group...')\n",
    "# Train the person group\n",
    "face_client.large_person_group.train(LARGE_PERSON_GROUP_ID)\n",
    "# Check training status\n",
    "while (True):\n",
    "    training_status = face_client.large_person_group.get_training_status(LARGE_PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        sys.exit('Training the large person group has failed.')\n",
    "    time.sleep(5)\n",
    "\n",
    "# Now that we have created and trained a large person group, we can retrieve data from it.\n",
    "# Returns a list[Person] of how many Persons were created/defined in the large person group.\n",
    "person_list_large = face_client.large_person_group_person.list(large_person_group_id=LARGE_PERSON_GROUP_ID, start='')\n",
    "\n",
    "print('Persisted Face IDs from {} large person group persons:'.format(len(person_list_large)))\n",
    "print()\n",
    "for person_large in person_list_large:\n",
    "    for persisted_face_id in person_large.persisted_face_ids:\n",
    "        print('The person {} has an image with ID: {}'.format(person_large.name, persisted_face_id))\n",
    "print()\n",
    "\n",
    "# After testing, delete the large person group, LargePersonGroupPersons also get deleted.\n",
    "face_client.large_person_group.delete(LARGE_PERSON_GROUP_ID)\n",
    "print(\"Deleted the large person group.\")\n",
    "print()\n",
    "'''\n",
    "END - Create/List/Delete Large Person Group\n",
    "'''\n",
    "\n",
    "'''\n",
    "FACELIST\n",
    "This example adds single-faced images from URL to a list, then gets data from the list.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('FACELIST OPERATIONS')\n",
    "print()\n",
    "\n",
    "# Create our list of URL images\n",
    "image_file_names = [\n",
    "    \"Family1-Dad1.jpg\",\n",
    "    \"Family1-Daughter1.jpg\",\n",
    "    \"Family1-Mom1.jpg\",\n",
    "    \"Family1-Son1.jpg\",\n",
    "    \"Family2-Lady1.jpg\",\n",
    "    \"Family2-Man1.jpg\",\n",
    "    \"Family3-Lady1.jpg\",\n",
    "    \"Family3-Man1.jpg\"\n",
    "]\n",
    "\n",
    "# Create an empty face list with an assigned ID.\n",
    "face_list_id = \"my-face-list\"\n",
    "print(\"Creating face list: {}...\".format(face_list_id))\n",
    "print()\n",
    "face_client.face_list.create(face_list_id=face_list_id, name=face_list_id)\n",
    "\n",
    "# Add each face in our array to the facelist\n",
    "for image_file_name in image_file_names:\n",
    "    face_client.face_list.add_face_from_url(\n",
    "        face_list_id=face_list_id,\n",
    "        url=IMAGE_BASE_URL + image_file_name,\n",
    "        user_data=image_file_name\n",
    "    )\n",
    "\n",
    "# Get persisted faces from the face list.\n",
    "the_face_list = face_client.face_list.get(face_list_id)\n",
    "if not the_face_list :\n",
    "    raise Exception(\"No persisted face in face list {}.\".format(face_list_id))\n",
    "\n",
    "print('Persisted face ids of images in face list:')\n",
    "print()\n",
    "for persisted_face in the_face_list.persisted_faces:\n",
    "    print(persisted_face.persisted_face_id)\n",
    "\n",
    "# Delete the face list, so you can retest (recreate) the list with same name.\n",
    "face_client.face_list.delete(face_list_id=face_list_id)\n",
    "print()\n",
    "print(\"Deleted the face list: {}.\\n\".format(face_list_id))\n",
    "'''\n",
    "END - FACELIST\n",
    "'''\n",
    "\n",
    "'''\n",
    "LARGE FACELIST\n",
    "This example adds single-faced images from URL to a large-capacity list, then gets data from the list.\n",
    "This list could handle up to 1 million images.\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('LARGE FACELIST OPERATIONS')\n",
    "print()\n",
    "\n",
    "# Create our list of URL images\n",
    "image_file_names_large = [\n",
    "    \"Family1-Dad1.jpg\",\n",
    "    \"Family1-Daughter1.jpg\",\n",
    "    \"Family1-Mom1.jpg\",\n",
    "    \"Family1-Son1.jpg\",\n",
    "    \"Family2-Lady1.jpg\",\n",
    "    \"Family2-Man1.jpg\",\n",
    "    \"Family3-Lady1.jpg\",\n",
    "    \"Family3-Man1.jpg\"\n",
    "]\n",
    "\n",
    "# Create an empty face list with an assigned ID.\n",
    "large_face_list_id = \"my-large-face-list\"\n",
    "print(\"Creating large face list: {}...\".format(large_face_list_id))\n",
    "print()\n",
    "face_client.large_face_list.create(large_face_list_id=large_face_list_id, name=large_face_list_id)\n",
    "\n",
    "# Add each face in our array to the large face list\n",
    "# Returns a PersistedFace\n",
    "for image_file_name in image_file_names_large:\n",
    "    face_client.large_face_list.add_face_from_url(\n",
    "        large_face_list_id=large_face_list_id,\n",
    "        url=IMAGE_BASE_URL + image_file_name,\n",
    "        user_data=image_file_name\n",
    "    )\n",
    "\n",
    "# Train the large list. Must train before getting any data from the list.\n",
    "# Training is not required of the regular-sized facelist.\n",
    "print(\"Train large face list {}\".format(large_face_list_id))\n",
    "print()\n",
    "face_client.large_face_list.train(large_face_list_id=large_face_list_id)\n",
    "\n",
    "# Get training status\n",
    "while (True):\n",
    "    training_status_list = face_client.large_face_list.get_training_status(large_face_list_id=large_face_list_id)\n",
    "    print(\"Training status: {}.\".format(training_status_list.status))\n",
    "    if training_status_list.status is TrainingStatusType.failed:\n",
    "        raise Exception(\"Training failed with message {}.\".format(training_status_list.message))\n",
    "    if (training_status_list.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "# Returns a list[PersistedFace]. Can retrieve data from each face.\n",
    "large_face_list_faces = face_client.large_face_list.list_faces(large_face_list_id)\n",
    "if not large_face_list_faces :\n",
    "    raise Exception(\"No persisted face in face list {}.\".format(large_face_list_id))\n",
    "\n",
    "print('Face ids of images in large face list:')\n",
    "print()\n",
    "for large_face in large_face_list_faces:\n",
    "    print(large_face.persisted_face_id)\n",
    "\n",
    "# Delete the large face list, so you can retest (recreate) the list with same name.\n",
    "face_client.large_face_list.delete(large_face_list_id=large_face_list_id)\n",
    "print()\n",
    "print(\"Deleted the large face list: {}.\\n\".format(large_face_list_id))\n",
    "'''\n",
    "END - LARGE FACELIST\n",
    "'''\n",
    "\n",
    "'''\n",
    "Delete Person Group\n",
    "For testing purposes, delete the person group made in the Person Group Operations.\n",
    "List the person groups in your account through the online testing console to check:\n",
    "https://westus2.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395248\n",
    "'''\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('DELETE PERSON GROUP')\n",
    "print()\n",
    "# <snippet_deletegroup>\n",
    "# Delete the main person group.\n",
    "face_client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "print(\"Deleted the person group {} from the source location.\".format(PERSON_GROUP_ID))\n",
    "print()\n",
    "# </snippet_deletegroup>\n",
    "\n",
    "print()\n",
    "print('-----------------------------')\n",
    "print()\n",
    "print('End of quickstart.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
